package canal

import (
	"encoding/json"
	"fmt"
	"log"
	"sync"
	"time"

	"gorm.io/gorm"
)

// DBMetaManager åŸºäºæ•°æ®åº“çš„å…ƒæ•°æ®ç®¡ç†å™¨
type DBMetaManager struct {
	db     *gorm.DB
	logger *log.Logger
	mu     sync.RWMutex
	cache  map[string]Position   // instanceID -> Position
	tables map[string]*TableMeta // schema.table -> TableMeta
}

// BinlogPosition binlog ä½ç½®è®°å½•
type BinlogPosition struct {
	ID         uint      `gorm:"primarykey"`
	InstanceID string    `gorm:"uniqueIndex;size:100;not null"`
	Filename   string    `gorm:"size:255"`
	Position   uint32    `gorm:"not null"`
	GTIDSet    string    `gorm:"type:text"`
	UpdatedAt  time.Time `gorm:"autoUpdateTime"`
	CreatedAt  time.Time `gorm:"autoCreateTime"`
}

// TableMetadata è¡¨å…ƒæ•°æ®è®°å½•
type TableMetadata struct {
	ID        uint      `gorm:"primarykey"`
	Schema    string    `gorm:"size:100;not null"`
	Table     string    `gorm:"size:100;not null"`
	Columns   string    `gorm:"type:text"` // JSON æ ¼å¼å­˜å‚¨åˆ—ä¿¡æ¯
	Types     string    `gorm:"type:text"` // JSON æ ¼å¼å­˜å‚¨ç±»å‹ä¿¡æ¯
	UpdatedAt time.Time `gorm:"autoUpdateTime"`
	CreatedAt time.Time `gorm:"autoCreateTime"`
}

// TableName æŒ‡å®šè¡¨å
func (BinlogPosition) TableName() string {
	return "binlog_positions"
}

// TableName æŒ‡å®šè¡¨å
func (TableMetadata) TableName() string {
	return "table_metadata"
}

// NewDBMetaManager åˆ›å»ºæ•°æ®åº“å…ƒæ•°æ®ç®¡ç†å™¨
func NewDBMetaManager(db *gorm.DB, logger *log.Logger) (*DBMetaManager, error) {
	manager := &DBMetaManager{
		db:     db,
		logger: logger,
		cache:  make(map[string]Position),
		tables: make(map[string]*TableMeta),
	}

	if err := db.AutoMigrate(&BinlogPosition{}, &TableMetadata{}); err != nil {
		return nil, fmt.Errorf("failed to auto migrate tables: %v", err)
	}

	// åŠ è½½ç¼“å­˜
	if err := manager.loadCache(); err != nil {
		return nil, fmt.Errorf("failed to load cache: %v", err)
	}

	return manager, nil
}

// loadCache åŠ è½½ç¼“å­˜
func (m *DBMetaManager) loadCache() error {
	// åŠ è½½ binlog ä½ç½®ç¼“å­˜
	var positions []BinlogPosition
	if err := m.db.Find(&positions).Error; err != nil {
		return fmt.Errorf("failed to load binlog positions: %v", err)
	}

	m.mu.Lock()
	for _, pos := range positions {
		m.cache[pos.InstanceID] = Position{
			Name:    pos.Filename,
			Pos:     pos.Position,
			GTIDSet: pos.GTIDSet,
		}
	}
	m.mu.Unlock()

	// åŠ è½½è¡¨å…ƒæ•°æ®ç¼“å­˜
	var tables []TableMetadata
	if err := m.db.Find(&tables).Error; err != nil {
		return fmt.Errorf("failed to load table metadata: %v", err)
	}

	m.mu.Lock()
	for _, table := range tables {
		key := fmt.Sprintf("%s.%s", table.Schema, table.Table)

		var columns []string
		var types []string

		if err := json.Unmarshal([]byte(table.Columns), &columns); err == nil {
			json.Unmarshal([]byte(table.Types), &types)
		}

		m.tables[key] = &TableMeta{
			Schema:  table.Schema,
			Table:   table.Table,
			Columns: columns,
			Types:   types,
		}
	}
	m.mu.Unlock()

	return nil
}

// SavePosition ä¿å­˜ binlog ä½ç½®
func (m *DBMetaManager) SavePosition(instanceID string, pos Position) error {
	m.mu.Lock()
	defer m.mu.Unlock()

	// è®°å½•æ—¥å¿—
	log.Printf("ğŸ’¾ Saving binlog position for instance %s: %s:%d", instanceID, pos.Name, pos.Pos)

	// æ›´æ–°ç¼“å­˜
	m.cache[instanceID] = pos
	log.Printf("âœ… Updated cache for instance %s", instanceID)

	// ä¿å­˜åˆ°æ•°æ®åº“
	binlogPos := BinlogPosition{
		InstanceID: instanceID,
		Filename:   pos.Name,
		Position:   pos.Pos,
		GTIDSet:    pos.GTIDSet,
	}
	log.Printf("ğŸ”§ Preparing to save position to database")

	// ä½¿ç”¨ UPSERT æ“ä½œ
	result := m.db.Where("instance_id = ?", instanceID).First(&BinlogPosition{})
	if result.Error == gorm.ErrRecordNotFound {
		// åˆ›å»ºæ–°è®°å½•
		log.Printf("ğŸ†• Creating new binlog position record for instance %s", instanceID)
		if err := m.db.Create(&binlogPos).Error; err != nil {
			log.Printf("âŒ Failed to create binlog position: %v", err)
			return fmt.Errorf("failed to create binlog position: %v", err)
		}
		log.Printf("âœ… Created new binlog position record for instance %s", instanceID)
	} else {
		// æ›´æ–°ç°æœ‰è®°å½•
		log.Printf("ğŸ”„ Updating existing binlog position record for instance %s", instanceID)
		if err := m.db.Where("instance_id = ?", instanceID).Updates(&binlogPos).Error; err != nil {
			log.Printf("âŒ Failed to update binlog position: %v", err)
			return fmt.Errorf("failed to update binlog position: %v", err)
		}
		log.Printf("âœ… Updated binlog position record for instance %s", instanceID)
	}

	log.Printf("ğŸ‰ Successfully saved binlog position for instance %s", instanceID)
	return nil
}

// LoadPosition åŠ è½½ binlog ä½ç½®
func (m *DBMetaManager) LoadPosition(instanceID string) (Position, error) {
	m.mu.RLock()
	defer m.mu.RUnlock()

	// è®°å½•æ—¥å¿—
	m.logger.Printf("ğŸ” Loading binlog position for instance %s", instanceID)

	// å…ˆä»ç¼“å­˜æŸ¥æ‰¾
	if pos, exists := m.cache[instanceID]; exists {
		m.logger.Printf("âœ… Found position in cache for instance %s: %s:%d", instanceID, pos.Name, pos.Pos)
		return pos, nil
	}

	m.logger.Printf("ğŸ”„ Position not found in cache for instance %s, loading from database", instanceID)
	// ä»æ•°æ®åº“è·å–
	var binlogPos BinlogPosition
	if err := m.db.Where("instance_id = ?", instanceID).First(&binlogPos).Error; err != nil {
		if err == gorm.ErrRecordNotFound {
			// è¿”å›é»˜è®¤ä½ç½®
			m.logger.Printf("âš ï¸  No position found in database for instance %s, returning default position", instanceID)
			return Position{Name: "", Pos: 4}, nil
		}
		m.logger.Printf("âŒ Failed to load binlog position from database for instance %s: %v", instanceID, err)
		return Position{}, fmt.Errorf("failed to load binlog position: %v", err)
	}

	pos := Position{
		Name:    binlogPos.Filename,
		Pos:     binlogPos.Position,
		GTIDSet: binlogPos.GTIDSet,
	}

	m.logger.Printf("âœ… Loaded position from database for instance %s: %s:%d", instanceID, pos.Name, pos.Pos)

	// æ›´æ–°ç¼“å­˜
	m.mu.Lock()
	m.cache[instanceID] = pos
	m.mu.Unlock()

	m.logger.Printf("ğŸ’¾ Updated cache for instance %s", instanceID)

	return pos, nil
}

// LoadTableMeta åŠ è½½è¡¨å…ƒæ•°æ®
func (m *DBMetaManager) LoadTableMeta(schema, table string) (*TableMeta, error) {
	m.mu.RLock()
	defer m.mu.RUnlock()

	// è®°å½•æ—¥å¿—
	m.logger.Printf("ğŸ” Loading table metadata for %s.%s", schema, table)

	// å…ˆä»ç¼“å­˜æŸ¥æ‰¾
	key := fmt.Sprintf("%s.%s", schema, table)
	if meta, exists := m.tables[key]; exists {
		m.logger.Printf("âœ… Found table metadata in cache for %s.%s", schema, table)
		return meta, nil
	}

	m.logger.Printf("ğŸ”„ Table metadata not found in cache for %s.%s, loading from database", schema, table)

	// ä»æ•°æ®åº“è·å–
	var tableMeta TableMetadata
	if err := m.db.Where("`schema` = ? AND `table` = ?", schema, table).First(&tableMeta).Error; err != nil {
		if err == gorm.ErrRecordNotFound {
			m.logger.Printf("âš ï¸  No table metadata found in database for %s.%s", schema, table)
			return nil, nil
		}
		m.logger.Printf("âŒ Failed to load table metadata from database for %s.%s: %v", schema, table, err)
		return nil, fmt.Errorf("failed to load table metadata: %v", err)
	}

	// è§£æåˆ—ä¿¡æ¯
	var columns []string
	var types []string
	if err := json.Unmarshal([]byte(tableMeta.Columns), &columns); err != nil {
		m.logger.Printf("âŒ Failed to unmarshal columns for %s.%s: %v", schema, table, err)
		return nil, fmt.Errorf("failed to unmarshal columns: %v", err)
	}
	if err := json.Unmarshal([]byte(tableMeta.Types), &types); err != nil {
		m.logger.Printf("âŒ Failed to unmarshal types for %s.%s: %v", schema, table, err)
		return nil, fmt.Errorf("failed to unmarshal types: %v", err)
	}

	meta := &TableMeta{
		Schema:  tableMeta.Schema,
		Table:   tableMeta.Table,
		Columns: columns,
		Types:   types,
	}

	m.logger.Printf("âœ… Loaded table metadata from database for %s.%s with %d columns", schema, table, len(columns))

	// æ›´æ–°ç¼“å­˜
	m.mu.Lock()
	m.tables[key] = meta
	m.mu.Unlock()

	m.logger.Printf("ğŸ’¾ Updated table metadata cache for %s.%s", schema, table)

	return meta, nil
}

// SaveTableMeta ä¿å­˜è¡¨å…ƒæ•°æ®
func (m *DBMetaManager) SaveTableMeta(schema, table string, meta *TableMeta) error {
	m.mu.Lock()
	defer m.mu.Unlock()

	m.logger.Printf("ğŸ’¾ Saving table metadata for %s.%s with %d columns", schema, table, len(meta.Columns))

	key := fmt.Sprintf("%s.%s", schema, table)
	m.tables[key] = meta

	// åºåˆ—åŒ–åˆ—ä¿¡æ¯
	columnsJSON, err := json.Marshal(meta.Columns)
	if err != nil {
		m.logger.Printf("âŒ Failed to marshal columns for %s.%s: %v", schema, table, err)
		return fmt.Errorf("failed to marshal columns: %v", err)
	}

	typesJSON, err := json.Marshal(meta.Types)
	if err != nil {
		m.logger.Printf("âŒ Failed to marshal types for %s.%s: %v", schema, table, err)
		return fmt.Errorf("failed to marshal types: %v", err)
	}

	tableMeta := TableMetadata{
		Schema:  schema,
		Table:   table,
		Columns: string(columnsJSON),
		Types:   string(typesJSON),
	}

	// ä½¿ç”¨ UPSERT æ“ä½œ
	m.logger.Printf("ğŸ”„ Upserting table metadata for %s.%s to database", schema, table)
	result := m.db.Where("`schema` = ? AND `table` = ?", schema, table).First(&TableMetadata{})
	if result.Error == gorm.ErrRecordNotFound {
		// åˆ›å»ºæ–°è®°å½•
		m.logger.Printf("ğŸ†• Creating new table metadata record for %s.%s", schema, table)
		if err := m.db.Create(&tableMeta).Error; err != nil {
			m.logger.Printf("âŒ Failed to create table metadata for %s.%s: %v", schema, table, err)
			return fmt.Errorf("failed to create table metadata: %v", err)
		}
	} else {
		// æ›´æ–°ç°æœ‰è®°å½•
		m.logger.Printf("ğŸ”„ Updating existing table metadata record for %s.%s", schema, table)
		if err := m.db.Where("`schema` = ? AND `table` = ?", schema, table).Updates(&tableMeta).Error; err != nil {
			m.logger.Printf("âŒ Failed to update table metadata for %s.%s: %v", schema, table, err)
			return fmt.Errorf("failed to update table metadata: %v", err)
		}
	}

	m.logger.Printf("âœ… Successfully saved table metadata for %s.%s", schema, table)

	return nil
}

// GetAllPositions è·å–æ‰€æœ‰ binlog ä½ç½®
func (m *DBMetaManager) GetAllPositions() map[string]Position {
	m.mu.RLock()
	defer m.mu.RUnlock()

	result := make(map[string]Position)
	for k, v := range m.cache {
		result[k] = v
	}
	return result
}

// GetAllTableMetas è·å–æ‰€æœ‰è¡¨å…ƒæ•°æ®
func (m *DBMetaManager) GetAllTableMetas() map[string]*TableMeta {
	m.mu.RLock()
	defer m.mu.RUnlock()

	result := make(map[string]*TableMeta)
	for k, v := range m.tables {
		result[k] = v
	}
	return result
}

// DeletePosition åˆ é™¤ binlog ä½ç½®
func (m *DBMetaManager) DeletePosition(instanceID string) error {
	m.mu.Lock()
	defer m.mu.Unlock()

	// ä»ç¼“å­˜åˆ é™¤
	delete(m.cache, instanceID)

	// ä»æ•°æ®åº“åˆ é™¤
	if err := m.db.Where("instance_id = ?", instanceID).Delete(&BinlogPosition{}).Error; err != nil {
		return fmt.Errorf("failed to delete binlog position: %v", err)
	}

	return nil
}

// DeleteTableMeta åˆ é™¤è¡¨å…ƒæ•°æ®
func (m *DBMetaManager) DeleteTableMeta(schema, table string) error {
	m.mu.Lock()
	defer m.mu.Unlock()

	key := fmt.Sprintf("%s.%s", schema, table)

	// ä»ç¼“å­˜åˆ é™¤
	delete(m.tables, key)

	// ä»æ•°æ®åº“åˆ é™¤
	if err := m.db.Where("`schema` = ? AND `table` = ?", schema, table).Delete(&TableMetadata{}).Error; err != nil {
		return fmt.Errorf("failed to delete table metadata: %v", err)
	}

	return nil
}

// Cleanup æ¸…ç†è¿‡æœŸæ•°æ®
func (m *DBMetaManager) Cleanup(olderThan time.Duration) error {
	cutoff := time.Now().Add(-olderThan)

	// æ¸…ç†è¿‡æœŸçš„ binlog ä½ç½®è®°å½•
	if err := m.db.Where("updated_at < ?", cutoff).Delete(&BinlogPosition{}).Error; err != nil {
		return fmt.Errorf("failed to cleanup old binlog positions: %v", err)
	}

	// æ¸…ç†è¿‡æœŸçš„è¡¨å…ƒæ•°æ®è®°å½•
	if err := m.db.Where("updated_at < ?", cutoff).Delete(&TableMetadata{}).Error; err != nil {
		return fmt.Errorf("failed to cleanup old table metadata: %v", err)
	}

	// é‡æ–°åŠ è½½ç¼“å­˜
	return m.loadCache()
}

// GetStats è·å–ç»Ÿè®¡ä¿¡æ¯
func (m *DBMetaManager) GetStats() map[string]interface{} {
	m.mu.RLock()
	defer m.mu.RUnlock()

	return map[string]interface{}{
		"positions_count":   len(m.cache),
		"table_metas_count": len(m.tables),
		"last_updated":      time.Now(),
	}
}
